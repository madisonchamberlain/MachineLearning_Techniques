{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHXJQNvCltGO"
      },
      "source": [
        "# Extra "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsaAwcqelqYX"
      },
      "source": [
        "  import warnings\n",
        "  warnings.filterwarnings('ignore')\n",
        "\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  from sklearn.preprocessing import RobustScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnhhpWqOIwNb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "531da9b3-5f58-4371-8d0a-1792663896da"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_path = '/content/drive/My Drive/day1.csv'\n",
        "day1 = pd.read_csv(my_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivK8zsokm0rf"
      },
      "source": [
        "# extract X columns we want to use by name using .loc\n",
        "day1 = day1.loc[:,['workingday','temp','atemp','hum', 'windspeed','tot']]\n",
        "# and use iloc to extract columns by number\n",
        "day1x = day1.iloc[:,0:5] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghTh4GtG1R5"
      },
      "source": [
        "# X = training set, newx = test set\n",
        "def kNN(X,Y,newx,k,regress=True,allK=False,leave1out=False,scaleX=True,scaler=StandardScaler()):\n",
        "\n",
        "  import warnings\n",
        "  warnings.filterwarnings('ignore')\n",
        "\n",
        "  import numpy as np\n",
        "\n",
        "  from sklearn.neighbors import KNeighborsRegressor\n",
        "  from sklearn.neighbors import KNeighborsClassifier \n",
        "  from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "  from statistics import mean \n",
        "  from statistics import mode\n",
        "  from collections import Counter\n",
        "\n",
        "  def kNNtype(neighbs,regress):\n",
        "    if regress:\n",
        "      knn = KNeighborsRegressor(n_neighbors=neighbs)\n",
        "    else:\n",
        "      knn = KNeighborsClassifier(n_neighbors=neighbs)\n",
        "    return knn\n",
        "\n",
        "  if scaler != StandardScaler():\n",
        "    scaler=scaler\n",
        "\n",
        "  if scaleX == True:\n",
        "    # scale feature columns for test and train data \n",
        "    columns_X = [list(X.columns)]\n",
        "    for feature in columns_X:\n",
        "      X[feature] = scaler.fit_transform(X[feature])\n",
        "      newx[feature] = scaler.fit_transform(newx[feature])\n",
        "\n",
        "  knn_all = pd.DataFrame()\n",
        "  if allK == True:\n",
        "    if leave1out == True:\n",
        "      nn_all = []\n",
        "      for j in list(newx.index.values.tolist()):\n",
        "      #for j in list(Y.index.values.tolist()):\n",
        "        knn_row = []\n",
        "        knn = kNNtype(k+1,regress)\n",
        "        knn.fit(X, Y)\n",
        "        test = pd.DataFrame(newx.loc[j,:])\n",
        "        nn = knn.kneighbors(test.T)[1][0]\n",
        "        for i in range(2,k+1):\n",
        "          nn1 = nn[1:i] # leave one out\n",
        "          test = list(Y.iloc[nn1])\n",
        "          if regress:\n",
        "            test = mean(test)\n",
        "          else:\n",
        "            c = Counter(test)\n",
        "            l = list(c.values())\n",
        "            ind = l.index(max(c.values()))\n",
        "            test = list(c.keys())[ind]\n",
        "            # count number of times the max class occurs and if there is a ty\n",
        "            # choose the second class with the max if index is even\n",
        "            if (l.count(max(l))) > 1 and (j % 2 !=0):\n",
        "              l[ind] = 0\n",
        "              ind = l.index(max(c.values()))\n",
        "              test = list(c.keys())[ind2]\n",
        "\n",
        "          knn_row.append(test)\n",
        "        knn_row = pd.DataFrame(knn_row)\n",
        "        knn_all = [knn_all, knn_row]\n",
        "        knn_all = pd.concat(knn_all,axis=1, ignore_index=True)\n",
        "        nn_all.append(list(nn1))\n",
        "      nn_all = np.array(nn_all)\n",
        "    else:\n",
        "        for i in range(1,k+1):\n",
        "          knn = kNNtype(i,regress)\n",
        "          knn.fit(X, Y)\n",
        "          test = knn.predict(newx)\n",
        "          knn_row = pd.DataFrame(test).T\n",
        "          knn_all = [knn_all, knn_row]\n",
        "          knn_all = pd.concat(knn_all,axis=0, ignore_index=True)\n",
        "        nn_all = knn.kneighbors(newx)[1]\n",
        "  else:\n",
        "    if leave1out == True:\n",
        "      knn_row = []\n",
        "      #for j in list(Y.index.values.tolist()):\n",
        "      for j in list(newx.index.values.tolist()):\n",
        "        knn = kNNtype(k,regress)\n",
        "        knn.fit(X, Y)\n",
        "        test = pd.DataFrame(newx.loc[j,:])\n",
        "        nn = knn.kneighbors(test.T)[1][0]\n",
        "\n",
        "        if (k % 2 != 0) and (regress == False):\n",
        "           nn1 = nn[2:len(nn)]\n",
        "        else:\n",
        "            nn1 = nn[1:len(nn)]\n",
        "\n",
        "        test = list(Y.iloc[nn1])\n",
        "        if regress:\n",
        "            test = mean(test)\n",
        "        else:\n",
        "          c = Counter(test)\n",
        "          l = list(c.values())\n",
        "          ind = l.index(max(c.values()))\n",
        "          test = list(c.keys())[ind]\n",
        "          # count number of times the max class occurs and if there is a ty\n",
        "          # choose the second class with the max if index is even\n",
        "          if (l.count(max(l))) > 1 and (j % 2 !=0):\n",
        "            l[ind] = 0\n",
        "            ind = l.index(max(c.values()))\n",
        "            test = list(c.keys())[ind2]\n",
        "\n",
        "        knn_row.append(test)\n",
        "      knn_all = pd.DataFrame(knn_row).T\n",
        "      nn_all = nn1\n",
        "    else:\n",
        "        knn = kNNtype(k,regress)\n",
        "        knn.fit(X, Y)\n",
        "        test = knn.predict(newx)\n",
        "        knn_all = pd.DataFrame(test)\n",
        "        nn_all = knn.kneighbors(newx)[1]\n",
        "\n",
        "  return knn_all, nn_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFwhoImu50El"
      },
      "source": [
        "def my_mode(list):\n",
        "  from collections import Counter \n",
        "  Ks_and_counts = dict(Counter(list))\n",
        "  max_count = max(Ks_and_counts.values())\n",
        "  most_common_Ks = []\n",
        "  for k, count in Ks_and_counts.items():\n",
        "    if count == max_count: \n",
        "      most_common_Ks.append(k)\n",
        "  if len(most_common_Ks) == len(list):\n",
        "    return \n",
        "  else:\n",
        "    return most_common_Ks[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Iir0H2gduO"
      },
      "source": [
        "def poulation_variance(list):\n",
        "  from statistics import mean\n",
        "  list_mean = mean(list)\n",
        "  sum_difs = 0\n",
        "  for item in list:\n",
        "    diff_squared = (item - list_mean)**2 \n",
        "    sum_difs += diff_squared \n",
        "  variance = sum_difs/len(list)\n",
        "  return variance\n",
        "\n",
        "def bestK(X,Y,maxK, start, stop):\n",
        "  # X = feature predictors, Y = value to be predicted, maxK = maximum k value to test, maxRow = maximum row to check the best k\n",
        "  \n",
        "  import statistics \n",
        "  import numpy as np\n",
        "\n",
        "  allpreds, nn = kNN(X,Y,X,maxK,allK = True,leave1out = True) \n",
        "  list_of_best_ks = []\n",
        "  for i in range(start, stop):\n",
        "    value = Y[i]\n",
        "    differences = []\n",
        "    for j in range(len(Y)):\n",
        "      for prediction in allpreds[j]:\n",
        "        difference = abs(value - prediction)\n",
        "        differences.append(difference)\n",
        "    indicies = np.argsort(differences)\n",
        "    best_k = indicies[0] + 2\n",
        "    list_of_best_ks.append(best_k)\n",
        "  common_k = my_mode(list_of_best_ks)  ### Note: I altered my_mode function from question 1; seen above\n",
        "  return common_k\n",
        "\n",
        "def p_hack(X,Y,n_subsets,maxK):\n",
        "  # X = feature predictors, Y = value to be predicted, maxK = maximum K to test, n_subsets = number of subsets from data\n",
        "  import statistics\n",
        "\n",
        "  subset_length = int(round(len(X)/n_subsets))\n",
        "  list_of_best_Ks = []\n",
        "  for i in range(n_subsets):\n",
        "    start = i*subset_length\n",
        "    stop = (i*subset_length) + subset_length\n",
        "    common_k = bestK(X[start:stop],Y[start:stop],maxK,start, stop) ### Note: I generated a new bestK function for the p_hack function seen above\n",
        "    list_of_best_Ks.append(common_k)\n",
        "  new_list = list(filter(None, list_of_best_Ks)) \n",
        "  var_in_k_value_between_subset = poulation_variance(new_list)  ### Note: my own population variance function is seen above \n",
        "  return round(var_in_k_value_between_subset, 4)\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ405Ma_gmm2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31d82192-d158-4ee0-83c8-a2d02cf850f2"
      },
      "source": [
        "X = day1.iloc[:,0:5] \n",
        "Y = day1.tot\n",
        "maxK = 4   # maxK cannot be larger than len(X)/n_subsets\n",
        "n_subsets = 70    # in this case, each subset will be of length 10\n",
        "\n",
        "\n",
        "p_hack = p_hack(X,Y,n_subsets,maxK)\n",
        "print(p_hack)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69.9623\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}